# ğŸ¥¤ Scrapper de Suplementos

Este proyecto es un **scraper automatizado en Node.js** que obtiene precios de suplementos desde una pÃ¡gina web, los compara con un snapshot previo y genera reportes diarios en **PDF** y **Excel**.  
AdemÃ¡s, envÃ­a notificaciones por **Telegram** y **correo electrÃ³nico** cuando detecta cambios en los precios.

---

## âœ¨ CaracterÃ­sticas

- âœ… Scraping de productos con precios de **pÃºblico** y **revendedor**.  
- âœ… ComparaciÃ³n con precios anteriores y detecciÃ³n de cambios.  
- âœ… GeneraciÃ³n automÃ¡tica de **PDF** y **Excel** con el detalle completo.  
- âœ… Notificaciones por **Telegram** de cambios detectados o errores.  
- âœ… EnvÃ­o de emails con reportes adjuntos.  
- âœ… Endpoint para ejecutar scraping bajo demanda.  
- âœ… **GitHub Action** que corre el scraper automÃ¡ticamente todos los dÃ­as.

---

## ğŸ›  TecnologÃ­as usadas

- **Node.js** + **Express** â€“ servidor y endpoints.  
- **Puppeteer** â€“ scraping y generaciÃ³n de PDF.  
- **ExcelJS** â€“ creaciÃ³n de reportes en Excel.  
- **EJS** â€“ template HTML para el reporte.  
- **Nodemailer** â€“ envÃ­o de emails con reportes.  
- **Telegram Bot API** â€“ notificaciones automÃ¡ticas.  
- **GitHub Actions** â€“ automatizaciÃ³n diaria.  

---

## ğŸ“¦ InstalaciÃ³n

Clona el repositorio y entra en la carpeta del proyecto:

```bash 
git clone https://github.com/usuario/scrapper-suplementos.git
cd scrapper-suplementos/server
```

Instala las dependencias:

```bash 
npm install
```

---

## âš™ï¸ ConfiguraciÃ³n

Crea un archivo `.env` en la raÃ­z del proyecto en la carpeta *server* con las siguientes variables:

# Server
- PORT=4000
- NODE_ENV=development

# Scraping
- BASE_URL=https://ejemplo.com/productos
- AUTH_URL=https://ejemplo.com/login
- VYJ_USER=tu_usuario
- VYJ_PASS=tu_password

# Notificaciones Telegram
- TELEGRAM_TOKEN=xxxxxxxxxxxxxxxxxxxx
- TELEGRAM_CHAT_ID=123456789   # Puedes poner mÃºltiples IDs separados por coma

# Email SMTP
- SMTP_HOST=smtp.tuservidor.com
- SMTP_PORT=587
- SMTP_USER=usuario@dominio.com
- SMTP_PASS=tu_password
- FROM_EMAIL=usuario@dominio.com
- TO_EMAIL=destinatario@dominio.com

---

## ğŸ”Œ Endpoints

El servidor expone algunos endpoints Ãºtiles:

- GET /api/update-prices-pdf  
  Ejecuta el scraping completo, genera PDF y Excel, envÃ­a notificaciones y emails.

- GET /api/update-prices  
  Ejecuta scraping y devuelve el Ãºltimo Excel generado para descarga.

Ejemplo:

curl http://localhost:4000/api/update-prices

---

## ğŸ¤– AutomatizaciÃ³n con GitHub Actions

El proyecto incluye un workflow en `.github/workflows/daily-info.yml` que ejecuta el scraper automÃ¡ticamente todos los dÃ­as.

El flujo:

1. Instala dependencias.  
2. Corre el scraper con `node server.js scrape`.  
3. EnvÃ­a notificaciones y emails si detecta cambios.  

Puedes personalizar la frecuencia editando el cron job en `daily-info.yml`.

---

## ğŸ“‚ Estructura del proyecto

```
ğŸ“¦bfm_suplementos
 â”£ ğŸ“‚.git
 â”£ ğŸ“‚.github
 â”ƒ â”— ğŸ“‚workflows
 â”ƒ â”ƒ â”— ğŸ“œdaily-info.yml
 â”£ ğŸ“‚client
 â”ƒ â”£ ğŸ“‚public
 â”ƒ â”ƒ â”— ğŸ“œvite.svg
 â”ƒ â”£ ğŸ“‚src
 â”ƒ â”ƒ â”£ ğŸ“‚assets
 â”ƒ â”ƒ â”ƒ â”— ğŸ“œreact.svg
 â”ƒ â”ƒ â”£ ğŸ“œApp.css
 â”ƒ â”ƒ â”£ ğŸ“œApp.jsx
 â”ƒ â”ƒ â”£ ğŸ“œindex.css
 â”ƒ â”ƒ â”— ğŸ“œmain.jsx
 â”ƒ â”£ ğŸ“œ.eslintrc.cjs
 â”ƒ â”£ ğŸ“œ.gitignore
 â”ƒ â”£ ğŸ“œindex.html
 â”ƒ â”£ ğŸ“œpackage-lock.json
 â”ƒ â”£ ğŸ“œpackage.json
 â”ƒ â”£ ğŸ“œREADME.md
 â”ƒ â”— ğŸ“œvite.config.js
 â”£ ğŸ“‚reports
 â”£ ğŸ“‚server
 â”ƒ â”£ ğŸ“‚reports
 â”ƒ â”£ ğŸ“œ.env
 â”ƒ â”£ ğŸ“œ.gitignore
 â”ƒ â”£ ğŸ“œlastPrices.json
 â”ƒ â”£ ğŸ“œpackage-lock.json
 â”ƒ â”£ ğŸ“œpackage.json
 â”ƒ â”£ ğŸ“œREADME.md
 â”ƒ â”£ ğŸ“œserver.js
 â”ƒ â”£ ğŸ“œtelegram.js
 â”ƒ â”— ğŸ“œtemplate.ejs
 â”£ ğŸ“œLICENSE
 â”— ğŸ“œREADME.md
```
---

## ğŸ“œ Licencia

Este proyecto se distribuye bajo la licencia **MIT**.  
Â¡Eres libre de usarlo y adaptarlo segÃºn tus necesidades!
